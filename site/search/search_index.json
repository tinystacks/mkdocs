{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction It\u2019s not easy shipping software to the cloud. A team aiming to deploy its application backends to a cloud provider such as Amazon Web Services needs to understand a dozen or more AWS features just to stand up a small project. And as the scale and size of your project grows, so does the complexity of its deployment. Many companies soon find themselves spending more time making their cloud applications secure and scalable than they do writing its core functionality. TinyStacks takes the drudgery out of deployment. Using TinyStacks, development teams can: Create a multi-stage (dev/test/stage/prod) CI/CD pipeline. TinyStacks deploys directly to your own AWS account, making it easy to deploy onto the cloud quickly while also providing transparency and flexibility. Use your favorite languages and frameworks Deploy applications to production to the cloud with minimal overhead Scale applications and APIs from hundreds of users to millions with little additional effort By deploying with TinyStacks, your team can spend less time building out DevOps architecture and more time building out the core features that make your application unique! What TinyStacks Does Below are some of the benefits that applications gain by deploying with TinyStacks. Use Your Favorite Languages and Frameworks. TinyStacks is language- and framework-agnostic. Our deployment processes will work with any application deployed via a Docker container. If your application currently isn\u2019t Dockerized, we have pre-built template files for the Node.js, Django, Express, and Flask frameworks to get you started. Full-Stack Architecture. TinyStacks creates everything your application requires to run on the cloud. It can even provision a Postgres database for data storage. Multi-Stage Deployments. TinyStacks supports defining as many development stages as you need. By default, we create a dev stage for development purposes. Using the TinyStacks dashboard, you can easily add a production stage and any intermediate stages - such as testing and staging - to your deployment process. Continuous Integration and Continuous Deployment. A TinyStacks stack is wired to a repository you own in GitHub or GitLab. By default, any changes you make to a stack\u2019s corresponding branch will be automatically compiled and updated in the currently running environment. You can also define manual approvals for any stage. Security by Default. TinyStacks incorporates the latest security best practices for cloud-based applications. Cost Efficiency. Controlling costs on the cloud is difficult. Finding the best price point for your application can require hundreds of hours of testing and experimentation. TinyStacks constantly monitor, test, and change the way we deploy stacks for our customers to get the best performance at the lowest price. (Read about a major change we made to our deployments that saved up to 40% on stack costs for our customers.) What TinyStacks Doesn\u2019t Do While TinyStacks conveys many benefits to development teams, it can\u2019t do everything . The following areas remain your responsibility: Hosting. TinyStacks is a DevOps orchestration framework, not a cloud hosting provider. All provisioned cloud capacity is run in your own cloud provider\u2019s accounts and you are directly responsible for all costs incurred. End to End Security. TinyStacks cannot make an insecure application secure. While Tinystacks takes multiple measures to ensure your infrastructure is secure by default, it does not guarantee the security of your application. It is up to you and your team to design and implement applications that adhere to the tenets of good security, such as defensive programming and the principle of least privilege.","title":"Introduction"},{"location":"#introduction","text":"It\u2019s not easy shipping software to the cloud. A team aiming to deploy its application backends to a cloud provider such as Amazon Web Services needs to understand a dozen or more AWS features just to stand up a small project. And as the scale and size of your project grows, so does the complexity of its deployment. Many companies soon find themselves spending more time making their cloud applications secure and scalable than they do writing its core functionality. TinyStacks takes the drudgery out of deployment. Using TinyStacks, development teams can: Create a multi-stage (dev/test/stage/prod) CI/CD pipeline. TinyStacks deploys directly to your own AWS account, making it easy to deploy onto the cloud quickly while also providing transparency and flexibility. Use your favorite languages and frameworks Deploy applications to production to the cloud with minimal overhead Scale applications and APIs from hundreds of users to millions with little additional effort By deploying with TinyStacks, your team can spend less time building out DevOps architecture and more time building out the core features that make your application unique!","title":"Introduction"},{"location":"#what-tinystacks-does","text":"Below are some of the benefits that applications gain by deploying with TinyStacks. Use Your Favorite Languages and Frameworks. TinyStacks is language- and framework-agnostic. Our deployment processes will work with any application deployed via a Docker container. If your application currently isn\u2019t Dockerized, we have pre-built template files for the Node.js, Django, Express, and Flask frameworks to get you started. Full-Stack Architecture. TinyStacks creates everything your application requires to run on the cloud. It can even provision a Postgres database for data storage. Multi-Stage Deployments. TinyStacks supports defining as many development stages as you need. By default, we create a dev stage for development purposes. Using the TinyStacks dashboard, you can easily add a production stage and any intermediate stages - such as testing and staging - to your deployment process. Continuous Integration and Continuous Deployment. A TinyStacks stack is wired to a repository you own in GitHub or GitLab. By default, any changes you make to a stack\u2019s corresponding branch will be automatically compiled and updated in the currently running environment. You can also define manual approvals for any stage. Security by Default. TinyStacks incorporates the latest security best practices for cloud-based applications. Cost Efficiency. Controlling costs on the cloud is difficult. Finding the best price point for your application can require hundreds of hours of testing and experimentation. TinyStacks constantly monitor, test, and change the way we deploy stacks for our customers to get the best performance at the lowest price. (Read about a major change we made to our deployments that saved up to 40% on stack costs for our customers.)","title":"What TinyStacks Does"},{"location":"#what-tinystacks-doesnt-do","text":"While TinyStacks conveys many benefits to development teams, it can\u2019t do everything . The following areas remain your responsibility: Hosting. TinyStacks is a DevOps orchestration framework, not a cloud hosting provider. All provisioned cloud capacity is run in your own cloud provider\u2019s accounts and you are directly responsible for all costs incurred. End to End Security. TinyStacks cannot make an insecure application secure. While Tinystacks takes multiple measures to ensure your infrastructure is secure by default, it does not guarantee the security of your application. It is up to you and your team to design and implement applications that adhere to the tenets of good security, such as defensive programming and the principle of least privilege.","title":"What TinyStacks Doesn\u2019t Do"},{"location":"architecture/","text":"When you create a new stack with TinyStacks, we stand up a number of resources in your AWS account. This section describes how each AWS resource fits into your stack, as well as the average costs for each AWS resource. Standard Scale vs. Hyperscale Most cloud developers have the same goal: deploying scalable applications at the best price point. To help you meet these goals, TinyStacks provides support for two separate application patterns: Standard scale applications that serve less than one million requests a day. Hyperscale applications applications that exceed one million requests a day. Both configurations will scale to meet user demand while avoiding site downtime. A standard scale configuration will be the most cost-efficient solution below the one million requests/day threshold. Once you exceed that threshold, a hyperscale configuration will yield the lowest spend. In the explanation that follows, we will discuss the points where you are offered a choice between standard scale and hyperscale configurations and detail how this influences your overall stack costs. The Role of Containers The heart of a TinyStacks application is a Docker container, a lightweight virtualized operating system that runs on top of other operating systems such as Linux or Windows. Before Docker, deploying applications at scale was fraught with difficulty. To run successfully, an application requires the correct configuration - the right version of its programming language runtime, shared libraries, and local state (environment variables, file system permissions, etc.). But system administrators were often forced to deploy applications across multiple servers with mismatched configurations. Docker simplifies deployment by packaging an application in a virtualized operating system that contains everything the application needs to run successfully, virtually eliminating the dependency issue. Once an application is verified to run successfully in its container, you can deploy as many running copies as you need to support your users at scale. You can also avoid bloat by shipping the application with exactly the dependencies it needs and nothing more. TinyStacks can deploy your Dockerized application easily. (If your application isn\u2019t Dockerized yet, no to worry - we have guides to assist you.) To run your container, we take advantage of two features in AWS: Amazon Elastic Container Registry (ECR) facilitates the storage and retrieval of Docker containers. Storing your Docker images in Amazon ECR makes it easy to deploy running instances of the image. It also provides a historical repository of images that simplifies version rollback. Amazon Elastic Container Service (ECS) is a container orchestration service that enables running Docker containers quickly and easily. Containers can be run on a set of virtual machines (a cluster) that you run and manage in your own account. Alternatively, they may be run using AWS Fargate , a serverless component of Amazon ECS that runs containers on computing capacity managed by AWS. For most deployments, TinyStacks manages its own ECS clusters on behalf of our customers. Architectural Components A stack consists of an application written on a specific application framework (such as Express, Flask, Django, Spring, etc.) packaged inside of a Docker container. TinyStacks creates the necessary architecture inside of your AWS account to run this Dockerized application in a scalable and highly available architecture on AWS. The following diagram shows the major architectural components in a stack. GitHub . A source code repository application based on the source control program Git. Stores the code for your application as well as some ancillary files needed in the stack deployment process. (TinyStacks also supports using GitLab as one\u2019s repository.) AWS CodePipeline . A continuous integration and continuous deployment service. Responsible for coordinating the build and deployment of the Docker container. AWS CodeBuild . A managed continuous integration service that builds source code into deployable applications. Comprises the steps in the CodePipeline. Amazon Elastic Container Registry (ECR) . Docker container storage service. Stores the Dockerized version of the application. Amazon Elastic Container Service (ECS) . Docker container orchestration service. Runs the latest version of the application. Amazon CloudWatch . Amazon\u2019s metrics, monitoring, and alerting service. Provides some basic alerts around application health and build/release status. Amazon API Gateway . A service for creating managed Application Programming Interfaces (API) at scale. Creates endpoints to the API functions defined by the application residing in the Docker container. Application Flow GitHub Stack Creation When you create a new stack in TinyStacks, you can choose whether to use a starter project or use an existing project already defined in your GitHub account. When you use a starter project, TinyStacks creates a new repository in your GitHub account that contains a basic Create/Read/Update/Delete (CRUD) data application with a handful of REST API endpoints. It also creates two YAML files that are used by TinyStacks for the AWS CodePipeline portion of the deployment: build.yml . Builds the Docker container and pushes it into the Amazon ECR instance. release.yml . Updates the running service in your Amazon ECS cluster. If you use an existing GitHub project, you will need to find the build.yml and release.yml files in the relevant TinyStacks template in Github and check them into your existing Github repository. Continuous Integration with Code Pipeline Your GitHub repository is connected to an AWS CodePipeline project. TinyStacks uses AWS CodePipeline to enable: Continuous integration , which ensures that your project is always built, packaged, and ready to be deployed. Continuous deployment , which deploys the latest package of your running project into the target environment. When you create a stack, you specify which branch of your GitHub repository you wish to connect to your AWS CodePipeline project. Whenever you commit a change to this branch, an AWS Lambda function does a full clone of the repository, creates a new ZIP file for the application, and uploads it to an Amazon S3 bucket. This change to the key in Amazon S3 triggers AWS CodePipeline to build and deploy your latest changes. Pushing Changes to Amazon ECR and Amazon ECS Your running application is hosted in Amazon ECS using an image stored in an Amazon ECR registry. TinyStacks creates both of these resources for you when it stands up your stack. Your ECS configuration consists of the following building blocks : An ECS cluster , a collection of virtual machines on which containers are run. TinyStacks manages its own ECS clusters on behalf of our customers\u2019 deployments. A task definition that specifies the container to run for your service. One or more running tasks , which correspond to a running instance of your container. A service , which ensures that a set number of running tasks are always accepting requests. By default, TinyStacks creates a single task for your service. However, this may be increased automatically up to five running tasks if your API is subject to high demand. (See below for more information on auto scaling.) Deployments through ECR and ECS are driven by your AWS CodePipeline project. This project contains two AWS CodeBuild projects: Build (specified by your project\u2019s build.yaml file). The Build project runs first and compiles a new Docker image containing your application\u2019s latest changes. It then pushes this new image up to the Amazon ECR container repository that TinyStacks created for your project. Release (specified by your project\u2019s release.yml file). After Build has run successfully, the Release project downloads and re-labels the current image pushed by the Build project to Amazon ECR. It then updates the running task definition on your Amazon Fargate cluster to ensure that your application is using the latest image. The output of both of these projects is available in the AWS CodePipeline console. TinyStacks also stores this output in Amazon CloudWatch Logs. Managed API Endpoints By default, your Amazon ECS container is hosted on an instance in a public subnet. However, the instance itself does not have a public IP address. TinyStacks uses Amazon API Gateway or Application Load Balancer to provide a publicly accessible endpoint onto your container\u2019s REST API methods. Amazon API Gateway provides you with fine-grained control over your REST API with support for configuring authorization, usage throttling, and advanced request routing, among other features. Application Load Balancer also provides routing support in addition to balancing requests across resource targets to avoid overwhelming any single resource. When you create a stack, you have a choice to use either API Gateway or Application Load Balancer. In general, applications receiving less than one million requests per day (standard scale applications) will find better price and performance using API Gateway. Applications serving more than one million requests per day (hyperscale applications) will receive better price/performance from using API Gateway. For more details, see our blog post comparing API Gateway with Application Load Balancer . Amazon CloudWatch for Auto Scaling As mentioned earlier, TinyStacks runs two instances of your Amazon ECS container by default. However, if your application is under heavy load, these instances may not be enough to handle the demand. TinyStacks uses the auto scaling feature of Amazon ECS to ensure your application can still run under heavy demand. Your stack defines several AWS CloudWatch alarms that monitor CPU utilization on the running containers associated with your task definition. If aggregate utilization for all running containers exceeds 75%, another container is launched, up to a maximum of five. Note that the scalability of a container is dependent upon good programming practices. Your application code should avoid storing state on disk or in memory on any given container, as you cannot predict which running container instance will service a given request. Cost of a TinyStacks Stack Note: Prices based on pricing of services in the US East (Virginia) data center as of July 2021. Pricing is subject to change without notice. Prices do not include any relevant taxes. The TinyStacks stack is designed, not just for reliability and scalability, but for cost-effectiveness as well. We estimate that running a typical stack in a development capacity will cost around $46 per month. Note that your actual costs may vary based on a couple of factors: Free Tier . If you have a new AWS account, you can consume a set amount of key AWS services for free every month for the first 12 months of your account\u2019s lifetime. If you exceed the free tier limits, you will incur additional charges and your costs will exceed those documented here. Usage . The estimates cited above assume light usage in a development/test environment. High-volume, production applications will incur higher costs. As end user usage of your application increases, costs will increase concomitantly. This is because the cloud services that support your application will automatically scale up and out to meet the increased demand, thus using additional computing resources. The two factors driving costs are the amount of traffic your application handles and the number of virtual machines required in your Amazon ECS cluster. Traffic Costs TinyStacks supports both standard scale (using Amazon API Gateway) and hyperscale (using Application Load Balancer) configurations. Your costs will scale differently on each configuration as your usage increases. In general, a hyperscale configuration will prove more cost-effective at a volume of 500,000 or more application requests per month. In a standard scale application, API Gateway costs will increase by around $1 for every additional million requests your application handles. In a hyperscale application, your costs will vary based on the number of Load Balancer Capacity Units (LCUs) your application consumes. LCUs are a complex metric, with a single LCU providing the following resources: 25 new connections per second 3,000 active connections every minute 1 GB of data sent to the Amazon EC2 instances in your Amazon ECS cluster 1,000 rules evaluated every second If your application exceeds any of these resource limits, you will pay for another LCU at a cost of around USD $0.008 per hour. You will pay for the largest number of LCUs required to accommodate your most demanding resource. For example, say that your application is receiving an average of 10,000 new connections every minute and is processing 3 GB of data every hour. In this instance, three LCUs would be enough to cover 3 GB of data. However, you will need 6.68 LCUs to cover 10,000 connections every minute (around 167 connections/second). According to the AWS Pricing Calculator , this would bring your LCU charges in us-east-1 up to around $40/month. Note that, in the above example, an application using API Gateway would be serving around 432 million connections per month for a total additional cost of $432/month. This makes it clear how much more economical it is to use Application Load Balancer when running at hyperscale. Amazon ECS Cluster Costs All Docker containers are hosted in an Amazon ECS cluster in your AWS account. An ECS cluster contains one or more instances of an Amazon EC2 virtual machine. By default, Tinystacks runs once EC2 instance in your cluster. As demand on your application grows, we will scale out and create a new cluster instance when the average CPU utilization across all cluster instances exceeds 70% for five minutes or longer. You can configure what instance size to use for your application when you create your stack. For standard scale applications, the t3.micro size is a good starter size that will limit your AWS spend (t3.micro instances will only run around USD $8/month). For hyperscale applications serving over 1 million requests/month, select m3.medium or m3.large depending on how CPU-intensive your workload is.","title":"Architecture"},{"location":"architecture/#standard-scale-vs-hyperscale","text":"Most cloud developers have the same goal: deploying scalable applications at the best price point. To help you meet these goals, TinyStacks provides support for two separate application patterns: Standard scale applications that serve less than one million requests a day. Hyperscale applications applications that exceed one million requests a day. Both configurations will scale to meet user demand while avoiding site downtime. A standard scale configuration will be the most cost-efficient solution below the one million requests/day threshold. Once you exceed that threshold, a hyperscale configuration will yield the lowest spend. In the explanation that follows, we will discuss the points where you are offered a choice between standard scale and hyperscale configurations and detail how this influences your overall stack costs.","title":"Standard Scale vs. Hyperscale"},{"location":"architecture/#the-role-of-containers","text":"The heart of a TinyStacks application is a Docker container, a lightweight virtualized operating system that runs on top of other operating systems such as Linux or Windows. Before Docker, deploying applications at scale was fraught with difficulty. To run successfully, an application requires the correct configuration - the right version of its programming language runtime, shared libraries, and local state (environment variables, file system permissions, etc.). But system administrators were often forced to deploy applications across multiple servers with mismatched configurations. Docker simplifies deployment by packaging an application in a virtualized operating system that contains everything the application needs to run successfully, virtually eliminating the dependency issue. Once an application is verified to run successfully in its container, you can deploy as many running copies as you need to support your users at scale. You can also avoid bloat by shipping the application with exactly the dependencies it needs and nothing more. TinyStacks can deploy your Dockerized application easily. (If your application isn\u2019t Dockerized yet, no to worry - we have guides to assist you.) To run your container, we take advantage of two features in AWS: Amazon Elastic Container Registry (ECR) facilitates the storage and retrieval of Docker containers. Storing your Docker images in Amazon ECR makes it easy to deploy running instances of the image. It also provides a historical repository of images that simplifies version rollback. Amazon Elastic Container Service (ECS) is a container orchestration service that enables running Docker containers quickly and easily. Containers can be run on a set of virtual machines (a cluster) that you run and manage in your own account. Alternatively, they may be run using AWS Fargate , a serverless component of Amazon ECS that runs containers on computing capacity managed by AWS. For most deployments, TinyStacks manages its own ECS clusters on behalf of our customers.","title":"The Role of Containers"},{"location":"architecture/#architectural-components","text":"A stack consists of an application written on a specific application framework (such as Express, Flask, Django, Spring, etc.) packaged inside of a Docker container. TinyStacks creates the necessary architecture inside of your AWS account to run this Dockerized application in a scalable and highly available architecture on AWS. The following diagram shows the major architectural components in a stack. GitHub . A source code repository application based on the source control program Git. Stores the code for your application as well as some ancillary files needed in the stack deployment process. (TinyStacks also supports using GitLab as one\u2019s repository.) AWS CodePipeline . A continuous integration and continuous deployment service. Responsible for coordinating the build and deployment of the Docker container. AWS CodeBuild . A managed continuous integration service that builds source code into deployable applications. Comprises the steps in the CodePipeline. Amazon Elastic Container Registry (ECR) . Docker container storage service. Stores the Dockerized version of the application. Amazon Elastic Container Service (ECS) . Docker container orchestration service. Runs the latest version of the application. Amazon CloudWatch . Amazon\u2019s metrics, monitoring, and alerting service. Provides some basic alerts around application health and build/release status. Amazon API Gateway . A service for creating managed Application Programming Interfaces (API) at scale. Creates endpoints to the API functions defined by the application residing in the Docker container.","title":"Architectural Components"},{"location":"architecture/#application-flow","text":"","title":"Application Flow"},{"location":"architecture/#github-stack-creation","text":"When you create a new stack in TinyStacks, you can choose whether to use a starter project or use an existing project already defined in your GitHub account. When you use a starter project, TinyStacks creates a new repository in your GitHub account that contains a basic Create/Read/Update/Delete (CRUD) data application with a handful of REST API endpoints. It also creates two YAML files that are used by TinyStacks for the AWS CodePipeline portion of the deployment: build.yml . Builds the Docker container and pushes it into the Amazon ECR instance. release.yml . Updates the running service in your Amazon ECS cluster. If you use an existing GitHub project, you will need to find the build.yml and release.yml files in the relevant TinyStacks template in Github and check them into your existing Github repository.","title":"GitHub Stack Creation"},{"location":"architecture/#continuous-integration-with-code-pipeline","text":"Your GitHub repository is connected to an AWS CodePipeline project. TinyStacks uses AWS CodePipeline to enable: Continuous integration , which ensures that your project is always built, packaged, and ready to be deployed. Continuous deployment , which deploys the latest package of your running project into the target environment. When you create a stack, you specify which branch of your GitHub repository you wish to connect to your AWS CodePipeline project. Whenever you commit a change to this branch, an AWS Lambda function does a full clone of the repository, creates a new ZIP file for the application, and uploads it to an Amazon S3 bucket. This change to the key in Amazon S3 triggers AWS CodePipeline to build and deploy your latest changes.","title":"Continuous Integration with Code Pipeline"},{"location":"architecture/#pushing-changes-to-amazon-ecr-and-amazon-ecs","text":"Your running application is hosted in Amazon ECS using an image stored in an Amazon ECR registry. TinyStacks creates both of these resources for you when it stands up your stack. Your ECS configuration consists of the following building blocks : An ECS cluster , a collection of virtual machines on which containers are run. TinyStacks manages its own ECS clusters on behalf of our customers\u2019 deployments. A task definition that specifies the container to run for your service. One or more running tasks , which correspond to a running instance of your container. A service , which ensures that a set number of running tasks are always accepting requests. By default, TinyStacks creates a single task for your service. However, this may be increased automatically up to five running tasks if your API is subject to high demand. (See below for more information on auto scaling.) Deployments through ECR and ECS are driven by your AWS CodePipeline project. This project contains two AWS CodeBuild projects: Build (specified by your project\u2019s build.yaml file). The Build project runs first and compiles a new Docker image containing your application\u2019s latest changes. It then pushes this new image up to the Amazon ECR container repository that TinyStacks created for your project. Release (specified by your project\u2019s release.yml file). After Build has run successfully, the Release project downloads and re-labels the current image pushed by the Build project to Amazon ECR. It then updates the running task definition on your Amazon Fargate cluster to ensure that your application is using the latest image. The output of both of these projects is available in the AWS CodePipeline console. TinyStacks also stores this output in Amazon CloudWatch Logs.","title":"Pushing Changes to Amazon ECR and Amazon ECS"},{"location":"architecture/#managed-api-endpoints","text":"By default, your Amazon ECS container is hosted on an instance in a public subnet. However, the instance itself does not have a public IP address. TinyStacks uses Amazon API Gateway or Application Load Balancer to provide a publicly accessible endpoint onto your container\u2019s REST API methods. Amazon API Gateway provides you with fine-grained control over your REST API with support for configuring authorization, usage throttling, and advanced request routing, among other features. Application Load Balancer also provides routing support in addition to balancing requests across resource targets to avoid overwhelming any single resource. When you create a stack, you have a choice to use either API Gateway or Application Load Balancer. In general, applications receiving less than one million requests per day (standard scale applications) will find better price and performance using API Gateway. Applications serving more than one million requests per day (hyperscale applications) will receive better price/performance from using API Gateway. For more details, see our blog post comparing API Gateway with Application Load Balancer .","title":"Managed API Endpoints"},{"location":"architecture/#amazon-cloudwatch-for-auto-scaling","text":"As mentioned earlier, TinyStacks runs two instances of your Amazon ECS container by default. However, if your application is under heavy load, these instances may not be enough to handle the demand. TinyStacks uses the auto scaling feature of Amazon ECS to ensure your application can still run under heavy demand. Your stack defines several AWS CloudWatch alarms that monitor CPU utilization on the running containers associated with your task definition. If aggregate utilization for all running containers exceeds 75%, another container is launched, up to a maximum of five. Note that the scalability of a container is dependent upon good programming practices. Your application code should avoid storing state on disk or in memory on any given container, as you cannot predict which running container instance will service a given request.","title":"Amazon CloudWatch for Auto Scaling"},{"location":"architecture/#cost-of-a-tinystacks-stack","text":"Note: Prices based on pricing of services in the US East (Virginia) data center as of July 2021. Pricing is subject to change without notice. Prices do not include any relevant taxes. The TinyStacks stack is designed, not just for reliability and scalability, but for cost-effectiveness as well. We estimate that running a typical stack in a development capacity will cost around $46 per month. Note that your actual costs may vary based on a couple of factors: Free Tier . If you have a new AWS account, you can consume a set amount of key AWS services for free every month for the first 12 months of your account\u2019s lifetime. If you exceed the free tier limits, you will incur additional charges and your costs will exceed those documented here. Usage . The estimates cited above assume light usage in a development/test environment. High-volume, production applications will incur higher costs. As end user usage of your application increases, costs will increase concomitantly. This is because the cloud services that support your application will automatically scale up and out to meet the increased demand, thus using additional computing resources. The two factors driving costs are the amount of traffic your application handles and the number of virtual machines required in your Amazon ECS cluster.","title":"Cost of a TinyStacks Stack"},{"location":"architecture/#traffic-costs","text":"TinyStacks supports both standard scale (using Amazon API Gateway) and hyperscale (using Application Load Balancer) configurations. Your costs will scale differently on each configuration as your usage increases. In general, a hyperscale configuration will prove more cost-effective at a volume of 500,000 or more application requests per month. In a standard scale application, API Gateway costs will increase by around $1 for every additional million requests your application handles. In a hyperscale application, your costs will vary based on the number of Load Balancer Capacity Units (LCUs) your application consumes. LCUs are a complex metric, with a single LCU providing the following resources: 25 new connections per second 3,000 active connections every minute 1 GB of data sent to the Amazon EC2 instances in your Amazon ECS cluster 1,000 rules evaluated every second If your application exceeds any of these resource limits, you will pay for another LCU at a cost of around USD $0.008 per hour. You will pay for the largest number of LCUs required to accommodate your most demanding resource. For example, say that your application is receiving an average of 10,000 new connections every minute and is processing 3 GB of data every hour. In this instance, three LCUs would be enough to cover 3 GB of data. However, you will need 6.68 LCUs to cover 10,000 connections every minute (around 167 connections/second). According to the AWS Pricing Calculator , this would bring your LCU charges in us-east-1 up to around $40/month. Note that, in the above example, an application using API Gateway would be serving around 432 million connections per month for a total additional cost of $432/month. This makes it clear how much more economical it is to use Application Load Balancer when running at hyperscale.","title":"Traffic Costs"},{"location":"architecture/#amazon-ecs-cluster-costs","text":"All Docker containers are hosted in an Amazon ECS cluster in your AWS account. An ECS cluster contains one or more instances of an Amazon EC2 virtual machine. By default, Tinystacks runs once EC2 instance in your cluster. As demand on your application grows, we will scale out and create a new cluster instance when the average CPU utilization across all cluster instances exceeds 70% for five minutes or longer. You can configure what instance size to use for your application when you create your stack. For standard scale applications, the t3.micro size is a good starter size that will limit your AWS spend (t3.micro instances will only run around USD $8/month). For hyperscale applications serving over 1 million requests/month, select m3.medium or m3.large depending on how CPU-intensive your workload is.","title":"Amazon ECS Cluster Costs"},{"location":"comparisons/","text":"In today\u2019s marketplace, you have no limit of choices when it comes to application deployment. We believe that TinyStacks offers the most transparent and flexible path for small shops and teams looking to grow up and out. Here\u2019s a short summary of how we stack up (pun absolutely intended) against other solutions. Amazon Web Services (AWS) We\u2019re big fans of AWS at TinyStacks. Our founders are former engineering leaders at AWS. Our own service - and the services we deploy for customers - depend on it. In terms of features and scalability, AWS is the undisputed leader in public cloud technology. But while AWS is great, onboarding to AWS can be challenging - especially for smaller shops. Its web of overlapping features can take weeks or even months to understand, let alone master. Bringing an application onto AWS in a scalable, secure manner typically requires at least one dedicated DevOps engineer. AWS has taken numerous steps in response to complaints about its complexity. One of the most popular is its Cloud Development Kit (CDK), a set of command-line tools intended to ease onboarding to AWS. However, the CDK supposes an existing knowledge of AWS services. It also currently supports only a small number of languages. TinyStacks aims to simplify your team\u2019s onboarding to AWS. Using TinyStacks, you can bring your existing app into the cloud in a matter of days or weeks as opposed to months. And, as your team\u2019s knowledge of AWS grows, you\u2019re free to incorporate the service\u2019s rich features into your own applications - all while using TinyStacks to deploy and monitor your stacks easily. AWS Amplify AWS Amplify is an AWS feature geared towards creating Web and mobile applications. Amplify supports creating both back-end resources - databases, authentication, and storage - along with static Web and mobile front ends that connect to them. Amplify may be the right choice for some projects. But it brings serious overhead that may inhibit its suitability for others. Amplify takes a walled garden approach to application development. It steers developers towards certain architectural choices - such as Amazon Cognito for authentication and DynamoDB for data storage - that may not be right for your app. Additionally, Amplify ships with a weighty (2MB) client library that could negatively impact application load times. Finally, AWS Amplify\u2019s pricing model somehow manages to make AWS pricing even more complicated. Unlike Amplify, the TinyStacks DevOps workflow can be used with a variety of development stacks. We also don\u2019t dictate critical architectural decisions such as data storage and authentication. Amazon Lightsail Lightsail is Amazon\u2019s Platform as a Service (PaaS) offering, enabling developers to deploy out- of-the-box packaged applications (like WordPress) and common development stacks with a few button clicks. Like other PaaS offerings, Lightsail works on a fixed-cost model, meaning that monthly charges are steady and predictable. However, Lightsail is only easy to use for the easy stuff. Lightsail deployments are based on creating individual Amazon EC2 instances. Lightsail deployments don\u2019t implement horizontal scaling by default, meaning they won\u2019t add new instances automatically to handle usage spikes. Setting up a horizontal scaling deployment with a load balancer on Lightsail is almost as involved as performing the same task on native AWS. TinyStacks combines ease of use with out-of-the-box scalability. A stack created by TinyStacks will always scale to meet the needs of your business. With a few clicks, you can deploy scalable architecture on AWS while only paying for what you use. Heroku Heroku is a PaaS provider, itself built on AWS, that makes it easy to deploy applications with low computational workloads. Teams that start with Heroku can have great success with the platform...for a while. But as your application grows and becomes more complex, it may start to outstrip the capabilities that Heroku offers. TinyStacks provides an easy-to-use bridge between services like Heroku and AWS. With TinyStacks, you can migrate your Heroku apps to the cloud and gain the following benefits: Performance . While Heroku performs well for small computational loads, many teams struggle with performance as their workloads and traffic increase. TinyStacks uses services such as Amazon ECS and API Gateway to ensure your application can scale to meet demand. Services . Heroku only exposes a fraction of AWS\u2019s rich feature set. TinyStacks provides the ease of use of a service like Heroku combined with the full power of AWS. You can start simple with your stack and slowly expand your application\u2019s features to take advantage of the full range of services that AWS has to offer. Cost . Heroku becomes increasingly expensive as your application scales out. TinyStacks works relentlessly to ensure you\u2019re getting the most cost-effective solution with your AWS stack deployments, no matter your application\u2019s size and scale. DigitalOcean Like Heroku, DigitalOcean can be a good choice for development teams when they start out. DigitalOcean\u2019s App Platform simplifies code deployment. And its fixed-price pricing model is alluring for firms just dipping their toes into the cloud. However, like Heroku, DigitalOcean offers a minimalistic set of features. As your business grows, it\u2019s likely you\u2019ll outgrow DigitalOcean. Plus, DigitalOcean doesn\u2019t provide any DevOps support or tools to manage application pipelines. If you want to have separate dev/test environments distinct from production or want to stand up a demo site for prospective customers, you\u2019ll need to roll it yourself. TinyStacks provides the ease of use of a platform like DigitalOcean backed by the power of AWS. Additionally, we make it easy to create and manage a full DevOps pipeline with separate dev, test, and prod environments - all without needing to hire a full-time DevOps engineer. Render Render is a Heroku competitor that provides a streamlined experience for deploying apps for a wide variety of developer frameworks. The company offers multiple higher-level features, such as Content Delivery Network (CDN) support and HTTP health checks. Like Heroku, however, Render deploys cloud resources on your behalf. The lack of transparent access to an underlying cloud provider limits growth. Eventually, you will run into scenarios that require access to the full capabilities of a service such as AWS. TinyStacks was built to make cloud deployment easier - not to limit your application\u2019s growth. Since TinyStacks applications run in your own AWS account, you retain full control and visibility over them. Managed Kubernetes Another option your team might be weighing is a managed Kubernetes approach. Kubernetes (\u201ck8s\u201d) is a popular container orchestration and management system that works with Docker and other containerization technologies. It\u2019s gained such a reputation for its scalability and reliability that every major cloud provider and many PaaS providers offer some form of managed Kubernetes hosting. The problem with Kubernetes? Complexity. For a team just transforming itself into a DevOps operation, Kubernetes has a daunting ramp-up time. It can take existing engineers months to ramp up on the system - and engineers with existing Kubernetes experience aren\u2019t cheap. Some PaaS-style Kubernetes solutions have managed to tame the complexity issue (somewhat) for first-time k8s developers. However, making them production-ready is often still a complex task that involves understanding and configuring multiple pieces of networking, logging, and monitoring software. And most managed k8s solutions don\u2019t solve the issue of standing up a full DevOps pipeline to flow changes between dev, test, and production. Finally, managed Kubernetes solutions tend to be pricey. For example, using AWS\u2019s managed solution, Elastic Kubernetes Service (EKS), will add an additional hourly cost on top of the underlying EC2 capacity used. TinyStacks does more than just simplify deployment - it supports a full DevOps architecture for growing teams. With a few button clicks, your team can create multiple stacks and bring additional rigor and reliability to your release process.","title":"How TinyStacks Stacks Up"},{"location":"comparisons/#amazon-web-services-aws","text":"We\u2019re big fans of AWS at TinyStacks. Our founders are former engineering leaders at AWS. Our own service - and the services we deploy for customers - depend on it. In terms of features and scalability, AWS is the undisputed leader in public cloud technology. But while AWS is great, onboarding to AWS can be challenging - especially for smaller shops. Its web of overlapping features can take weeks or even months to understand, let alone master. Bringing an application onto AWS in a scalable, secure manner typically requires at least one dedicated DevOps engineer. AWS has taken numerous steps in response to complaints about its complexity. One of the most popular is its Cloud Development Kit (CDK), a set of command-line tools intended to ease onboarding to AWS. However, the CDK supposes an existing knowledge of AWS services. It also currently supports only a small number of languages. TinyStacks aims to simplify your team\u2019s onboarding to AWS. Using TinyStacks, you can bring your existing app into the cloud in a matter of days or weeks as opposed to months. And, as your team\u2019s knowledge of AWS grows, you\u2019re free to incorporate the service\u2019s rich features into your own applications - all while using TinyStacks to deploy and monitor your stacks easily.","title":"Amazon Web Services (AWS)"},{"location":"comparisons/#aws-amplify","text":"AWS Amplify is an AWS feature geared towards creating Web and mobile applications. Amplify supports creating both back-end resources - databases, authentication, and storage - along with static Web and mobile front ends that connect to them. Amplify may be the right choice for some projects. But it brings serious overhead that may inhibit its suitability for others. Amplify takes a walled garden approach to application development. It steers developers towards certain architectural choices - such as Amazon Cognito for authentication and DynamoDB for data storage - that may not be right for your app. Additionally, Amplify ships with a weighty (2MB) client library that could negatively impact application load times. Finally, AWS Amplify\u2019s pricing model somehow manages to make AWS pricing even more complicated. Unlike Amplify, the TinyStacks DevOps workflow can be used with a variety of development stacks. We also don\u2019t dictate critical architectural decisions such as data storage and authentication.","title":"AWS Amplify"},{"location":"comparisons/#amazon-lightsail","text":"Lightsail is Amazon\u2019s Platform as a Service (PaaS) offering, enabling developers to deploy out- of-the-box packaged applications (like WordPress) and common development stacks with a few button clicks. Like other PaaS offerings, Lightsail works on a fixed-cost model, meaning that monthly charges are steady and predictable. However, Lightsail is only easy to use for the easy stuff. Lightsail deployments are based on creating individual Amazon EC2 instances. Lightsail deployments don\u2019t implement horizontal scaling by default, meaning they won\u2019t add new instances automatically to handle usage spikes. Setting up a horizontal scaling deployment with a load balancer on Lightsail is almost as involved as performing the same task on native AWS. TinyStacks combines ease of use with out-of-the-box scalability. A stack created by TinyStacks will always scale to meet the needs of your business. With a few clicks, you can deploy scalable architecture on AWS while only paying for what you use.","title":"Amazon Lightsail"},{"location":"comparisons/#heroku","text":"Heroku is a PaaS provider, itself built on AWS, that makes it easy to deploy applications with low computational workloads. Teams that start with Heroku can have great success with the platform...for a while. But as your application grows and becomes more complex, it may start to outstrip the capabilities that Heroku offers. TinyStacks provides an easy-to-use bridge between services like Heroku and AWS. With TinyStacks, you can migrate your Heroku apps to the cloud and gain the following benefits: Performance . While Heroku performs well for small computational loads, many teams struggle with performance as their workloads and traffic increase. TinyStacks uses services such as Amazon ECS and API Gateway to ensure your application can scale to meet demand. Services . Heroku only exposes a fraction of AWS\u2019s rich feature set. TinyStacks provides the ease of use of a service like Heroku combined with the full power of AWS. You can start simple with your stack and slowly expand your application\u2019s features to take advantage of the full range of services that AWS has to offer. Cost . Heroku becomes increasingly expensive as your application scales out. TinyStacks works relentlessly to ensure you\u2019re getting the most cost-effective solution with your AWS stack deployments, no matter your application\u2019s size and scale.","title":"Heroku"},{"location":"comparisons/#digitalocean","text":"Like Heroku, DigitalOcean can be a good choice for development teams when they start out. DigitalOcean\u2019s App Platform simplifies code deployment. And its fixed-price pricing model is alluring for firms just dipping their toes into the cloud. However, like Heroku, DigitalOcean offers a minimalistic set of features. As your business grows, it\u2019s likely you\u2019ll outgrow DigitalOcean. Plus, DigitalOcean doesn\u2019t provide any DevOps support or tools to manage application pipelines. If you want to have separate dev/test environments distinct from production or want to stand up a demo site for prospective customers, you\u2019ll need to roll it yourself. TinyStacks provides the ease of use of a platform like DigitalOcean backed by the power of AWS. Additionally, we make it easy to create and manage a full DevOps pipeline with separate dev, test, and prod environments - all without needing to hire a full-time DevOps engineer.","title":"DigitalOcean"},{"location":"comparisons/#render","text":"Render is a Heroku competitor that provides a streamlined experience for deploying apps for a wide variety of developer frameworks. The company offers multiple higher-level features, such as Content Delivery Network (CDN) support and HTTP health checks. Like Heroku, however, Render deploys cloud resources on your behalf. The lack of transparent access to an underlying cloud provider limits growth. Eventually, you will run into scenarios that require access to the full capabilities of a service such as AWS. TinyStacks was built to make cloud deployment easier - not to limit your application\u2019s growth. Since TinyStacks applications run in your own AWS account, you retain full control and visibility over them.","title":"Render"},{"location":"comparisons/#managed-kubernetes","text":"Another option your team might be weighing is a managed Kubernetes approach. Kubernetes (\u201ck8s\u201d) is a popular container orchestration and management system that works with Docker and other containerization technologies. It\u2019s gained such a reputation for its scalability and reliability that every major cloud provider and many PaaS providers offer some form of managed Kubernetes hosting. The problem with Kubernetes? Complexity. For a team just transforming itself into a DevOps operation, Kubernetes has a daunting ramp-up time. It can take existing engineers months to ramp up on the system - and engineers with existing Kubernetes experience aren\u2019t cheap. Some PaaS-style Kubernetes solutions have managed to tame the complexity issue (somewhat) for first-time k8s developers. However, making them production-ready is often still a complex task that involves understanding and configuring multiple pieces of networking, logging, and monitoring software. And most managed k8s solutions don\u2019t solve the issue of standing up a full DevOps pipeline to flow changes between dev, test, and production. Finally, managed Kubernetes solutions tend to be pricey. For example, using AWS\u2019s managed solution, Elastic Kubernetes Service (EKS), will add an additional hourly cost on top of the underlying EC2 capacity used. TinyStacks does more than just simplify deployment - it supports a full DevOps architecture for growing teams. With a few button clicks, your team can create multiple stacks and bring additional rigor and reliability to your release process.","title":"Managed Kubernetes"},{"location":"concepts/","text":"The following page defines the key concepts you need to know to use TinyStacks effectively. Standing Up a DevOps Infrastructure To deploy an application, development teams must define two major components. First, they need a way to stand up the cloud infrastructure needed to run their application. Second, they need a way to stand up this infrastructure, on-demand, whenever they have a feature or bug fix to ship. Infrastructure as Code Before the advent of the cloud, companies had to stand up physical infrastructure - servers in data centers connected to high-speed networks - in order to deploy Web-based applications. This changed with the advent of cloud service providers such as AWS, which provide computing capacity on demand. Instead of standing up permanent capacity, companies could now rent what they needed, shut it down when they were finished, and pay for only what they used. Cloud computing capacity can be activated manually - e.g., via the AWS Management Console. It can also be activated automatically - via a programming language such as Python, or a declarative language such as AWS CloudFormation . This paves the way for infrastructure as code : the ability to provision the computing capacity an application requires in an automated, repeatable fashion. With infrastructure as code, a development team can deploy multiple releases of their application using the same template. Additionally, they can stand up and shut down environments with ease: a test environment can be spun up to verify an application\u2019s integrity, and then shut down at the end of the testing run to conserve costs. A team can also deploy multiple types of environments - from an environment for developers to a full production-ready deployment - using the same code. Continuous Integration and Continuous Deployment As discussed in the Architectural overview, TinyStacks aims to simplify two processes critical to rapid application development: continuous integration and continuous deployment . In continuous integration, changes to an application\u2019s codebase are compiled immediately once they are committed to a branch in a repository. This ensures that the codebase is healthy and can produce a viable release. In continuous deployment, the output produced by continuous integration is made available for usage and testing. Continuous deployment leverages infrastructure as code to deploy, not just the application, but all the underlying computing capacity the application requires. The goal of continuous deployment is to put a new, verified release into customer\u2019s hands as quickly as possible. The process used to compile and bundle an application and push it through various phases of testing is called a release pipeline . TinyStacks Automates The Release Process Both infrastructure as code and release pipelines are powerful concepts. The problem is that, historically, they both take considerable time and resources to implement. TinyStacks automates and simplifies the task of building a full end-to-end release process. It leverages infrastructure as code to deploy your applications with all of the cloud computing capacity and capabilities that it requires. Further, it provides a simple, intuitive user interface that you and your team can use to construct your own release pipelines. Services A service corresponds to a traditional microservice or Web application. Stacks A stack is a TinyStacks project that consists of a microservice or other Web application. A stack contains at least one stage (see below) and often contains multiple stages. Stages A stage is a deployment intended for testing or use at a specific point in the development process. A release pipeline typically consists of multiple stages. Development teams use stages to perform quality verification of a release before making it available to customers. While the type and number of stages will differ from team to team (or even project to project), a typical split is: A dev stage for testing brand new feature additions or bug fixes that work locally on a developer\u2019s environment. A test stage where automated test suites can be run alongside manual testing by other team members or internal stakeholders. A staging or preprod (pre-production) stage that mimics production and is used by internal employees and select customers to vet the final release. A prod (production) stage that hosts the customer-facing version of your application. A check-in to a stack\u2019s Git repository will flow through each stage in the order shown on the TinyStacks Dashboard. Each stage will build and deploy the checked-in changes to that stage\u2019s stack. If the build and deployment are successful, the changes flow to the next stage, where they are also built and deployed. If an error occurs, the change will not flow to the next stage.","title":"Concepts"},{"location":"concepts/#standing-up-a-devops-infrastructure","text":"To deploy an application, development teams must define two major components. First, they need a way to stand up the cloud infrastructure needed to run their application. Second, they need a way to stand up this infrastructure, on-demand, whenever they have a feature or bug fix to ship.","title":"Standing Up a DevOps Infrastructure"},{"location":"concepts/#infrastructure-as-code","text":"Before the advent of the cloud, companies had to stand up physical infrastructure - servers in data centers connected to high-speed networks - in order to deploy Web-based applications. This changed with the advent of cloud service providers such as AWS, which provide computing capacity on demand. Instead of standing up permanent capacity, companies could now rent what they needed, shut it down when they were finished, and pay for only what they used. Cloud computing capacity can be activated manually - e.g., via the AWS Management Console. It can also be activated automatically - via a programming language such as Python, or a declarative language such as AWS CloudFormation . This paves the way for infrastructure as code : the ability to provision the computing capacity an application requires in an automated, repeatable fashion. With infrastructure as code, a development team can deploy multiple releases of their application using the same template. Additionally, they can stand up and shut down environments with ease: a test environment can be spun up to verify an application\u2019s integrity, and then shut down at the end of the testing run to conserve costs. A team can also deploy multiple types of environments - from an environment for developers to a full production-ready deployment - using the same code.","title":"Infrastructure as Code"},{"location":"concepts/#continuous-integration-and-continuous-deployment","text":"As discussed in the Architectural overview, TinyStacks aims to simplify two processes critical to rapid application development: continuous integration and continuous deployment . In continuous integration, changes to an application\u2019s codebase are compiled immediately once they are committed to a branch in a repository. This ensures that the codebase is healthy and can produce a viable release. In continuous deployment, the output produced by continuous integration is made available for usage and testing. Continuous deployment leverages infrastructure as code to deploy, not just the application, but all the underlying computing capacity the application requires. The goal of continuous deployment is to put a new, verified release into customer\u2019s hands as quickly as possible. The process used to compile and bundle an application and push it through various phases of testing is called a release pipeline .","title":"Continuous Integration and Continuous Deployment"},{"location":"concepts/#tinystacks-automates-the-release-process","text":"Both infrastructure as code and release pipelines are powerful concepts. The problem is that, historically, they both take considerable time and resources to implement. TinyStacks automates and simplifies the task of building a full end-to-end release process. It leverages infrastructure as code to deploy your applications with all of the cloud computing capacity and capabilities that it requires. Further, it provides a simple, intuitive user interface that you and your team can use to construct your own release pipelines.","title":"TinyStacks Automates The Release Process"},{"location":"concepts/#services","text":"A service corresponds to a traditional microservice or Web application.","title":"Services"},{"location":"concepts/#stacks","text":"A stack is a TinyStacks project that consists of a microservice or other Web application. A stack contains at least one stage (see below) and often contains multiple stages.","title":"Stacks"},{"location":"concepts/#stages","text":"A stage is a deployment intended for testing or use at a specific point in the development process. A release pipeline typically consists of multiple stages. Development teams use stages to perform quality verification of a release before making it available to customers. While the type and number of stages will differ from team to team (or even project to project), a typical split is: A dev stage for testing brand new feature additions or bug fixes that work locally on a developer\u2019s environment. A test stage where automated test suites can be run alongside manual testing by other team members or internal stakeholders. A staging or preprod (pre-production) stage that mimics production and is used by internal employees and select customers to vet the final release. A prod (production) stage that hosts the customer-facing version of your application. A check-in to a stack\u2019s Git repository will flow through each stage in the order shown on the TinyStacks Dashboard. Each stage will build and deploy the checked-in changes to that stage\u2019s stack. If the build and deployment are successful, the changes flow to the next stage, where they are also built and deployed. If an error occurs, the change will not flow to the next stage.","title":"Stages"},{"location":"create-stack/","text":"The following guide is for first-time TinyStacks users. Follow these instructions to launch one of our sample applications on AWS in under 15 minutes! Prerequisites You will need the following resources set up before you start using TinyStacks: A Git account with either GitHub or GitLab . An AWS account . All of the resources TinyStacks creates for you will be hosted in an AWS account that you own. Don't worry - you cna get started without any previous knowledge of AWS! Configure Git connection When you first log in to TinyStacks, you\u2019ll need to wire up a supported Git repository account as well as an AWS account. TinyStacks supports using Git repositories hosted on GitHub or GitLab. Select which Git service you plan to use: GitHub or Gitlab. A separate window will open. If you are not logged in to your selected service, you will be prompted to log in now. Once logged in, you will need to grant authorization for TinyStacks to access your GitHub or GitLab account. This will allow us to add a repository to your account (if you use one of our starter projects) or read an existing repository (if you use your own project). Configure AWS account Once you've authorized your Git account, you will be prompted to authorize an AWS account. This account will host all of the cloud resources required by your application. If you have not logged in to your AWS account recently, you will be prompted to do so. Once you have logged in to AWS, you will see the following screen, which prompts you to create an AWS CloudFormation stack in your AWS account. This step is necessary in order to proceed and fully connect your account. This CloudFormation template will create an AWS Identity and Access Management (IAM) role that TinyStacks will assume in order to create resources in your account. ( Note : Some elements of the screen above have been blurred out for security reasons.) To create this stack, select the box I acknowledge that AWS CloudFormation might create IAM resources . Then, click the Create Stack button. After creating the stack, tab back to the previous tab containing the TinyStacks window. Once the stack has completed creating, TinyStacks will automatically detect this and move you to the next step in the stack creation process. Once you see the screen below, you can proceed. Select a starter project Next, you'll be prompted to select a project. You can either select a TinyStacks starter project or use your own project. For this guide, we'll be using a starter project, so go ahead and click the Starter projects button. The TinyStacks starter projects are simple Create/Read/Update/Delete (CRUD) database applications written in the application framework of your choice. You can click the name of any starter project in the window below to see its repository on GitHub and check out its README, which gives a detailed description of the app's code and deployment architecture. Once you select a project, TinyStacks will copy its code into your Git account, where you can use it as a basis for further development. For this guide, let's create an Express project . Next to Express in the window above, click Deploy . On the next screen, you'll be prompted to give your project a name. Choose a simple, short name that's 20 characters or less. (The name will be used as a prefix for some of the resources in your AWS account, so we want to keep it short to avoid going over naming length limits in AWS.) Customize your deployment You have one more step to go and then you're ready to launch your stack! After clicking Deploy , you'll see the screen below, which enables you to fine-tune multiple settings for the first stage of your stack. This screen visualizes all of the AWS resources that TinyStacks will use or create on your behalf. These components and what they contribute to your stack are discussed in detail in our architectural guide . Briefly, they include: Your Git repo (either GitHub or GitLab) that holds your application code. AWS CodeBuild to build and deploy your project as a Docker container. An Amazon Elastic Container Repository (ECR) repo for storing your Docker container's versions. An Amazon Elastic Container Service (ECS) cluster for hosting your running Docker containers. Amazon API Gateway for routing traffic to your application's exposed endpoints. Amazon CloudWatch for monitoring performance and storing application logs. An optional database for storing application data. Additionally, you can see and configure several additional options: The AWS pricing breakdown gives you a sense of what you'll per month for your stack in its current configuration. You can define Environment variables as name-value pairs that will be exposed as environment variables to your running application's Docker container. If a tile has a gear icon in the upper right corner, you can click it to configure advanced options for that tile. Configurable options include: Database . Click Enable to create an Amazon RDS Postgres database for your account. Use the settings option to select an existing database instead and to configure other database-related options. Amazon ECS . Configure build and scale settings for your Amazon ECS cluster, such as the size of the Amazon EC2 instances used in your cluster. Amazon API Gateway . Choose between using Amazon API Gateway or Application Load Balancer for front end application routing. You can change any of these options now or change them later, after your original deployment. Your stack will also build as is, without any additional configuration. For now, start the creation of your first stack by clicking Build . Testing your stack Your stack will take a few minutes to build. Once it's done, you'll be taken to the Stacks page on your TinyStacks account, where you can see your running stack listed. Click on your stack's name to navigate to the Stack Details page. This page shows your stack and all of the stages you've defined. The initial stack creation process creates a single stage named dev . You can use the Add stage button to add more stages at any time. For now, let's tets out the dev stack and ensure it's working. On the lower right corner of the dev box, click Copy endpoint . Then, open a new tab in your Web browser, paste in the copied URL, and press Enter . You should navigate to the Express application's ping page, which should return a string reading Healthy connection . You can also test other endpoints of the API as defined by the Express app README. For example, to add an item to the application's memory, you can use the following command on Linux systems. Be sure to replace my-domain-name with the domain portion of your application's URL, which will be of the form unique-id.execute-api.us-east-1.amazonaws.com : curl -H \"Content-Type: application/json\" -X PUT -d '{\"title\":\"my title\", \"content\" : \"my content\"}' \"https://my-domain-name/item\" On Windows Powershell, use the following command: $item = @{ title=\"my title\" content=\"my content\" } $json = $item | ConvertTo-Json $response = Invoke-WebRequest 'https://my-domain-name/local-item' -Method Put -Body $json -ContentType 'application/json' -UseBasicParsing If everything is configured correctly, you'll receive a 200 HTTP response status code for the operation. Congratulations - you've deployed your first stack! Push your first commit Your stack is configured to deploy any changes you make to your code automatically to your dev stage. To see this in action, let's make a small change to your code. Navigate to your Git repo. You can do this easily by clicking on the GitHub or GitLab icon on your stack's tile on the Stack Details page. In the repository, navigate to the file src/server.ts . Copy the /ping method and create a new method called /pong . Return a custom message from the method in the response: app.get(\"/ping\", (req, res) => { res.status(200).send(\"Setting a custom message\"); }); Next, commit your change. In the GitHub UI, you can do this by clicking the Commit changes button at the bottom of the page you're editing. Return to TinyStacks and to the Stack Details page for your stack. Within a couple of minutes, you should see that TinyStacks has picked up the change to your application and is applying the changes to your stack. The first tile will spin while it is building your changes into a new Docker container. Then, you will see the dev stage update as the change is deployed. Wait until the change has propagated to your dev stage. Then, test the /pong URL with cUrl to see your new endpoint. On Linux, run the following command: curl https://my-domain-name/pong On Windows Powershell, use: curl https://my-domain-name/pong -UseBasicParsing","title":"Create Your First Stack"},{"location":"create-stack/#prerequisites","text":"You will need the following resources set up before you start using TinyStacks: A Git account with either GitHub or GitLab . An AWS account . All of the resources TinyStacks creates for you will be hosted in an AWS account that you own. Don't worry - you cna get started without any previous knowledge of AWS!","title":"Prerequisites"},{"location":"create-stack/#configure-git-connection","text":"When you first log in to TinyStacks, you\u2019ll need to wire up a supported Git repository account as well as an AWS account. TinyStacks supports using Git repositories hosted on GitHub or GitLab. Select which Git service you plan to use: GitHub or Gitlab. A separate window will open. If you are not logged in to your selected service, you will be prompted to log in now. Once logged in, you will need to grant authorization for TinyStacks to access your GitHub or GitLab account. This will allow us to add a repository to your account (if you use one of our starter projects) or read an existing repository (if you use your own project).","title":"Configure Git connection"},{"location":"create-stack/#configure-aws-account","text":"Once you've authorized your Git account, you will be prompted to authorize an AWS account. This account will host all of the cloud resources required by your application. If you have not logged in to your AWS account recently, you will be prompted to do so. Once you have logged in to AWS, you will see the following screen, which prompts you to create an AWS CloudFormation stack in your AWS account. This step is necessary in order to proceed and fully connect your account. This CloudFormation template will create an AWS Identity and Access Management (IAM) role that TinyStacks will assume in order to create resources in your account. ( Note : Some elements of the screen above have been blurred out for security reasons.) To create this stack, select the box I acknowledge that AWS CloudFormation might create IAM resources . Then, click the Create Stack button. After creating the stack, tab back to the previous tab containing the TinyStacks window. Once the stack has completed creating, TinyStacks will automatically detect this and move you to the next step in the stack creation process. Once you see the screen below, you can proceed.","title":"Configure AWS account"},{"location":"create-stack/#select-a-starter-project","text":"Next, you'll be prompted to select a project. You can either select a TinyStacks starter project or use your own project. For this guide, we'll be using a starter project, so go ahead and click the Starter projects button. The TinyStacks starter projects are simple Create/Read/Update/Delete (CRUD) database applications written in the application framework of your choice. You can click the name of any starter project in the window below to see its repository on GitHub and check out its README, which gives a detailed description of the app's code and deployment architecture. Once you select a project, TinyStacks will copy its code into your Git account, where you can use it as a basis for further development. For this guide, let's create an Express project . Next to Express in the window above, click Deploy . On the next screen, you'll be prompted to give your project a name. Choose a simple, short name that's 20 characters or less. (The name will be used as a prefix for some of the resources in your AWS account, so we want to keep it short to avoid going over naming length limits in AWS.)","title":"Select a starter project"},{"location":"create-stack/#customize-your-deployment","text":"You have one more step to go and then you're ready to launch your stack! After clicking Deploy , you'll see the screen below, which enables you to fine-tune multiple settings for the first stage of your stack. This screen visualizes all of the AWS resources that TinyStacks will use or create on your behalf. These components and what they contribute to your stack are discussed in detail in our architectural guide . Briefly, they include: Your Git repo (either GitHub or GitLab) that holds your application code. AWS CodeBuild to build and deploy your project as a Docker container. An Amazon Elastic Container Repository (ECR) repo for storing your Docker container's versions. An Amazon Elastic Container Service (ECS) cluster for hosting your running Docker containers. Amazon API Gateway for routing traffic to your application's exposed endpoints. Amazon CloudWatch for monitoring performance and storing application logs. An optional database for storing application data. Additionally, you can see and configure several additional options: The AWS pricing breakdown gives you a sense of what you'll per month for your stack in its current configuration. You can define Environment variables as name-value pairs that will be exposed as environment variables to your running application's Docker container. If a tile has a gear icon in the upper right corner, you can click it to configure advanced options for that tile. Configurable options include: Database . Click Enable to create an Amazon RDS Postgres database for your account. Use the settings option to select an existing database instead and to configure other database-related options. Amazon ECS . Configure build and scale settings for your Amazon ECS cluster, such as the size of the Amazon EC2 instances used in your cluster. Amazon API Gateway . Choose between using Amazon API Gateway or Application Load Balancer for front end application routing. You can change any of these options now or change them later, after your original deployment. Your stack will also build as is, without any additional configuration. For now, start the creation of your first stack by clicking Build .","title":"Customize your deployment"},{"location":"create-stack/#testing-your-stack","text":"Your stack will take a few minutes to build. Once it's done, you'll be taken to the Stacks page on your TinyStacks account, where you can see your running stack listed. Click on your stack's name to navigate to the Stack Details page. This page shows your stack and all of the stages you've defined. The initial stack creation process creates a single stage named dev . You can use the Add stage button to add more stages at any time. For now, let's tets out the dev stack and ensure it's working. On the lower right corner of the dev box, click Copy endpoint . Then, open a new tab in your Web browser, paste in the copied URL, and press Enter . You should navigate to the Express application's ping page, which should return a string reading Healthy connection . You can also test other endpoints of the API as defined by the Express app README. For example, to add an item to the application's memory, you can use the following command on Linux systems. Be sure to replace my-domain-name with the domain portion of your application's URL, which will be of the form unique-id.execute-api.us-east-1.amazonaws.com : curl -H \"Content-Type: application/json\" -X PUT -d '{\"title\":\"my title\", \"content\" : \"my content\"}' \"https://my-domain-name/item\" On Windows Powershell, use the following command: $item = @{ title=\"my title\" content=\"my content\" } $json = $item | ConvertTo-Json $response = Invoke-WebRequest 'https://my-domain-name/local-item' -Method Put -Body $json -ContentType 'application/json' -UseBasicParsing If everything is configured correctly, you'll receive a 200 HTTP response status code for the operation. Congratulations - you've deployed your first stack!","title":"Testing your stack"},{"location":"create-stack/#push-your-first-commit","text":"Your stack is configured to deploy any changes you make to your code automatically to your dev stage. To see this in action, let's make a small change to your code. Navigate to your Git repo. You can do this easily by clicking on the GitHub or GitLab icon on your stack's tile on the Stack Details page. In the repository, navigate to the file src/server.ts . Copy the /ping method and create a new method called /pong . Return a custom message from the method in the response: app.get(\"/ping\", (req, res) => { res.status(200).send(\"Setting a custom message\"); }); Next, commit your change. In the GitHub UI, you can do this by clicking the Commit changes button at the bottom of the page you're editing. Return to TinyStacks and to the Stack Details page for your stack. Within a couple of minutes, you should see that TinyStacks has picked up the change to your application and is applying the changes to your stack. The first tile will spin while it is building your changes into a new Docker container. Then, you will see the dev stage update as the change is deployed. Wait until the change has propagated to your dev stage. Then, test the /pong URL with cUrl to see your new endpoint. On Linux, run the following command: curl https://my-domain-name/pong On Windows Powershell, use: curl https://my-domain-name/pong -UseBasicParsing","title":"Push your first commit"},{"location":"existing/","text":"In our guide to creating your first stack , we showed you how to launch one of our sample applications as a fully scalable deployment on the cloud. But it's just as easy to package and deploy an existing application! Prerequisites You will need the following resources set up before you start using TinyStacks: A Git account with either GitHub or GitLab . An AWS account . All of the resources TinyStacks creates for you will be hosted in an AWS account that you own. Don't worry - you cna get started without any previous knowledge of AWS! Configure Git connection When you first log in to TinyStacks, you\u2019ll need to wire up a supported Git repository account as well as an AWS account. TinyStacks supports using Git repositories hosted on GitHub or GitLab. Select which Git service you plan to use: GitHub or Gitlab. A separate window will open. If you are not logged in to your selected service, you will be prompted to log in now. Once logged in, you will need to grant authorization for TinyStacks to access your GitHub or GitLab account. This will allow us to add a repository to your account (if you use one of our starter projects) or read an existing repository (if you use your own project). Configure AWS account Once you've authorized your Git account, you will be prompted to authorize an AWS account. This account will host all of the cloud resources required by your application. If you have not logged in to your AWS account recently, you will be prompted to do so. Once you have logged in to AWS, you will see the following screen, which prompts you to create an AWS CloudFormation stack in your AWS account. This step is necessary in order to proceed and fully connect your account. This CloudFormation template will create an AWS Identity and Access Management (IAM) role that TinyStacks will assume in order to create resources in your account. ( Note : Some elements of the screen above have been blurred out for security reasons.) To create this stack, select the box I acknowledge that AWS CloudFormation might create IAM resources . Then, click the Create Stack button. After creating the stack, tab back to the previous tab containing the TinyStacks window. Once the stack has completed creating, TinyStacks will automatically detect this and move you to the next step in the stack creation process. Once you see the screen below, you can proceed. Create a new stack Next, you'll be prompted to select a project. You can either select a TinyStacks starter project or use your own project. For this guide, we'll be using your own project. Select My projects . You should see a list of all of the repositories available in your Git account. Find the repository whose code you are going to deploy and click Prepare to deploy . You should now be on the Prepare your repository page. Check the deployment template files into your Git repository When you choose to deploy code from an existing repository, TinyStacks checks your repo to see if it contains three files: A Dockerfile . This file contains the instructions for preparing your Docker container, which will run your application code. Your container will need to contain your application framework (Express, Flask, Django, etc.), as well as any configuration files and environment variables necessary to run your application. A build.yml file, which AWS CodeDeploy will use to create the latest version of your Docker container and store it in an Amazon Elastic Code Repository (ECR) repo in your AWS account. A release.yml file, which AWS CodeDeploy will use to run your Docker container on an Amazon Elastic Container Service (ECS) cluster hosted in your AWS account. For more details on the elements of a TinyStacks deployment, see our architecture page . Note : If your app is already Dockerized (has a Dockerfile), you do not need to replace it with our Dockerfile. We only provide a Dockerfile for the benefit of teams who have no yet containerized their applications. Since your Docker container must contain the framework required by your application, it's important that you click the Framework dropdown and select whatever framework your application uses. This will ensure that the Dockerfile that you download can successfully run your application. Once you've selected the correct framework, click download all files at the bottom of the page to download all three files as a zip file. Unzip this file and check in all of the missing files for your application to the root of your repository. The root directory of your repo should look something like the example below after you are done: ( Note : This example is for an Express app - your project may have different files if it is using a different framework. The important thing is that these three files are checked into the root of your repository.) Once you are done, click Next . Name your project and select the deployment branch Next, give your project a name. Since this name will be used as a prefix for many of your AWS resources, keep it to 20 characters or less. You will also need to select a deployment branch. This is the branch of your Git repository on which new check ins will trigger a new deployment. There are two other settings on this page you can optionally configure: Port : If the application in your Docker container is using a port other than the default (80) to serve traffic, enter it here. Custom health check : AWS services such as Application Load Balancer use health checks to determine if an instance of your application is running correctly. Instances that fail a health check are destroyed and replaced with healthy instances. By default, Tinystacks uses the endpoint /ping to check application health. If you use a different endpoint, specify it here. When you're done, click Next . Finalizing deployment options On the next screen, you will be asked to review your infrastructure before launching your application on TinyStacks. Click Review infrastructure to see the infrastructure that TinyStacks will create in your AWS account and to set any additional options. The options on this page are the same ones discussed in the guide to creating your first stack . Please review that document for a full description of the available options. For users launching an existing application, the Review Infrastructure page is a good time to consider what runtime configuration your application requires to run successfully. In particular, you should consider: Data storage . You can create a new Postgres database in the Databases tile. If you need to use a different database, you can create or import an existing database into an Amazon RDS instance and then select it on this screen. Environment variables . If you're using a database outside of AWS or need to specify additional configuration information for your application, use the Environment Variables link on this page to define simple name-value pairs. These variables will be exposed as Linux environment variables to your application running in its Docker container. Once you're ready, click the Build button to build your Docker container and deploy it to AWS. Testing your stack Your stack will take a few minutes to build. Once it's done, you'll be taken to the Stacks page on your TinyStacks account, where you can see your running stack listed. Click on your stack's name to navigate to the Stack Details page. This page shows your stack and all of the stages you've defined. The initial stack creation process creates a single stage named dev . You can use the Add stage button to add more stages at any time. For now, let's tets out the dev stack and ensure it's working. On the lower right corner of the dev box, click Copy endpoint . You can use this base URL to access a valid page or REST API call in your application. If everything is configured correctly, you should see your application return an appropriate response to your request. Properly containerizing your application By following the steps above, your application should deploy and run in the cloud. However, you may notice some issues running your code if you haven't prepared your application to run in a container. As explained in our architectural overview , a Docker container is a virtualized operating system that contains all of the executable files, scripts, shared libraries, configuration files and other dependencies required for your application to run. In order to scale your application to handle upwards of millions of requests, your AWS account will need to run multiple copies of this container across multiple virtual machines. If your application has been designed as a monolithic application, it may make certain assumptions about its runtime environment that won't hold true after your application is containerized. If you are seeing errors or strange behavior in your application, here are a few things to consider. Filesystem storage Each running Docker container instance has its own virtualized filesystem. Data written to this filesystem in one running container instance won't be visible to other running instances. Ensure that any data that all container instances must access is written to a shared location - e.g., a database, a cloud storage service like Amazon S3, or an in-memory cache server like Amazon ElastiCache . Configuration Each running container instance will need its own copies of whatever configuration files your application might need. If you need to update any of these configuration files, you will need either to push changes through Git, or store the configuration in a location that all of your running container instances can access dynamically (such as Amazon S3).","title":"Deploy an Existing Application"},{"location":"existing/#prerequisites","text":"You will need the following resources set up before you start using TinyStacks: A Git account with either GitHub or GitLab . An AWS account . All of the resources TinyStacks creates for you will be hosted in an AWS account that you own. Don't worry - you cna get started without any previous knowledge of AWS!","title":"Prerequisites"},{"location":"existing/#configure-git-connection","text":"When you first log in to TinyStacks, you\u2019ll need to wire up a supported Git repository account as well as an AWS account. TinyStacks supports using Git repositories hosted on GitHub or GitLab. Select which Git service you plan to use: GitHub or Gitlab. A separate window will open. If you are not logged in to your selected service, you will be prompted to log in now. Once logged in, you will need to grant authorization for TinyStacks to access your GitHub or GitLab account. This will allow us to add a repository to your account (if you use one of our starter projects) or read an existing repository (if you use your own project).","title":"Configure Git connection"},{"location":"existing/#configure-aws-account","text":"Once you've authorized your Git account, you will be prompted to authorize an AWS account. This account will host all of the cloud resources required by your application. If you have not logged in to your AWS account recently, you will be prompted to do so. Once you have logged in to AWS, you will see the following screen, which prompts you to create an AWS CloudFormation stack in your AWS account. This step is necessary in order to proceed and fully connect your account. This CloudFormation template will create an AWS Identity and Access Management (IAM) role that TinyStacks will assume in order to create resources in your account. ( Note : Some elements of the screen above have been blurred out for security reasons.) To create this stack, select the box I acknowledge that AWS CloudFormation might create IAM resources . Then, click the Create Stack button. After creating the stack, tab back to the previous tab containing the TinyStacks window. Once the stack has completed creating, TinyStacks will automatically detect this and move you to the next step in the stack creation process. Once you see the screen below, you can proceed.","title":"Configure AWS account"},{"location":"existing/#create-a-new-stack","text":"Next, you'll be prompted to select a project. You can either select a TinyStacks starter project or use your own project. For this guide, we'll be using your own project. Select My projects . You should see a list of all of the repositories available in your Git account. Find the repository whose code you are going to deploy and click Prepare to deploy . You should now be on the Prepare your repository page.","title":"Create a new stack"},{"location":"existing/#check-the-deployment-template-files-into-your-git-repository","text":"When you choose to deploy code from an existing repository, TinyStacks checks your repo to see if it contains three files: A Dockerfile . This file contains the instructions for preparing your Docker container, which will run your application code. Your container will need to contain your application framework (Express, Flask, Django, etc.), as well as any configuration files and environment variables necessary to run your application. A build.yml file, which AWS CodeDeploy will use to create the latest version of your Docker container and store it in an Amazon Elastic Code Repository (ECR) repo in your AWS account. A release.yml file, which AWS CodeDeploy will use to run your Docker container on an Amazon Elastic Container Service (ECS) cluster hosted in your AWS account. For more details on the elements of a TinyStacks deployment, see our architecture page . Note : If your app is already Dockerized (has a Dockerfile), you do not need to replace it with our Dockerfile. We only provide a Dockerfile for the benefit of teams who have no yet containerized their applications. Since your Docker container must contain the framework required by your application, it's important that you click the Framework dropdown and select whatever framework your application uses. This will ensure that the Dockerfile that you download can successfully run your application. Once you've selected the correct framework, click download all files at the bottom of the page to download all three files as a zip file. Unzip this file and check in all of the missing files for your application to the root of your repository. The root directory of your repo should look something like the example below after you are done: ( Note : This example is for an Express app - your project may have different files if it is using a different framework. The important thing is that these three files are checked into the root of your repository.) Once you are done, click Next .","title":"Check the deployment template files into your Git repository"},{"location":"existing/#name-your-project-and-select-the-deployment-branch","text":"Next, give your project a name. Since this name will be used as a prefix for many of your AWS resources, keep it to 20 characters or less. You will also need to select a deployment branch. This is the branch of your Git repository on which new check ins will trigger a new deployment. There are two other settings on this page you can optionally configure: Port : If the application in your Docker container is using a port other than the default (80) to serve traffic, enter it here. Custom health check : AWS services such as Application Load Balancer use health checks to determine if an instance of your application is running correctly. Instances that fail a health check are destroyed and replaced with healthy instances. By default, Tinystacks uses the endpoint /ping to check application health. If you use a different endpoint, specify it here. When you're done, click Next .","title":"Name your project and select the deployment branch"},{"location":"existing/#finalizing-deployment-options","text":"On the next screen, you will be asked to review your infrastructure before launching your application on TinyStacks. Click Review infrastructure to see the infrastructure that TinyStacks will create in your AWS account and to set any additional options. The options on this page are the same ones discussed in the guide to creating your first stack . Please review that document for a full description of the available options. For users launching an existing application, the Review Infrastructure page is a good time to consider what runtime configuration your application requires to run successfully. In particular, you should consider: Data storage . You can create a new Postgres database in the Databases tile. If you need to use a different database, you can create or import an existing database into an Amazon RDS instance and then select it on this screen. Environment variables . If you're using a database outside of AWS or need to specify additional configuration information for your application, use the Environment Variables link on this page to define simple name-value pairs. These variables will be exposed as Linux environment variables to your application running in its Docker container. Once you're ready, click the Build button to build your Docker container and deploy it to AWS.","title":"Finalizing deployment options"},{"location":"existing/#testing-your-stack","text":"Your stack will take a few minutes to build. Once it's done, you'll be taken to the Stacks page on your TinyStacks account, where you can see your running stack listed. Click on your stack's name to navigate to the Stack Details page. This page shows your stack and all of the stages you've defined. The initial stack creation process creates a single stage named dev . You can use the Add stage button to add more stages at any time. For now, let's tets out the dev stack and ensure it's working. On the lower right corner of the dev box, click Copy endpoint . You can use this base URL to access a valid page or REST API call in your application. If everything is configured correctly, you should see your application return an appropriate response to your request.","title":"Testing your stack"},{"location":"existing/#properly-containerizing-your-application","text":"By following the steps above, your application should deploy and run in the cloud. However, you may notice some issues running your code if you haven't prepared your application to run in a container. As explained in our architectural overview , a Docker container is a virtualized operating system that contains all of the executable files, scripts, shared libraries, configuration files and other dependencies required for your application to run. In order to scale your application to handle upwards of millions of requests, your AWS account will need to run multiple copies of this container across multiple virtual machines. If your application has been designed as a monolithic application, it may make certain assumptions about its runtime environment that won't hold true after your application is containerized. If you are seeing errors or strange behavior in your application, here are a few things to consider.","title":"Properly containerizing your application"},{"location":"existing/#filesystem-storage","text":"Each running Docker container instance has its own virtualized filesystem. Data written to this filesystem in one running container instance won't be visible to other running instances. Ensure that any data that all container instances must access is written to a shared location - e.g., a database, a cloud storage service like Amazon S3, or an in-memory cache server like Amazon ElastiCache .","title":"Filesystem storage"},{"location":"existing/#configuration","text":"Each running container instance will need its own copies of whatever configuration files your application might need. If you need to update any of these configuration files, you will need either to push changes through Git, or store the configuration in a location that all of your running container instances can access dynamically (such as Amazon S3).","title":"Configuration"},{"location":"tinystacks-how-do-i/","text":"So you've got your first stack up and running. Now, it's time to tailor your stack to meet your team's needs. The following guide addresses the most common use cases for maintaining and expanding your stack. Basic How Do I ...add a new stage? When TinyStacks created your stack, we created a single stage for you called dev . As discussed in our concepts documentation , your team will likely want at least two stages - one for development and one for production. This allows you to test changes in your dev stage before releasing them to customers. To add a second stage, navigate to your Stacks page and select your stack by clicking on its name. The next page will show all of the stages currently defined for your stack. To add a new stage, click the Add stage button. On the New stack stage screen, you can configure your new stage. In the next screenshot, we've supplied a sample dialog for a prod stage that we explain in detail below: Stage name . Must be unique within this stack. Should indicate the role that this stage plays in your stack - e.g., dev, test, staging, prod, etc. In this case, we use the name prod to represent our production stage. Database . Enables adding a new Postgres database or another existing Amazon RDS database to your stack. For now, we'll leave this option blank. Require manual approval . By default, if a change checked into a branch is built and deployed successfully by one stage, it will propagate automatically to the next stage. In most cases, however, your team will want to test and approve changes manually before pushing them into production. Since we're creating a production stage here, we'll check this box. Amazon API Gateway vs. Application Load Balancer . Here, you can choose how you want to route requests to your application based on whether you expect your application will need to operate at standard scale or hyperscale. For now, we'll leave this to the default of Amazon API Gateway. For more information on scale settings, consult our architectural overview . Enable caching . Whether to cache responses through API Gateway. This option is only available if using Amazon API Gateway. Once you've configured your stage to suit your needs, click Create new stage . The new stage will run and create, building the code that you most recently checked in to the stack's associated Git branch. ...pass custom variables and configuration data to each stage? It's likely that your application will need various runtime variables set in order to run. For example, you may need to supply credentials to a data store, such as DynamoDB, or information on how to connect to other microservices on which the application depends. Each stage of your application will likely need its own custom runtime variables, as the configuration and the resources to which your application connects will vary by stage. TinyStacks makes it easy to set runtime variables on your application that are unique to each stage. This enables you to have different configuration settings for your application depending on whether it's in dev, test, or production. To add or change runtime variables, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. In the Stage dropdown on the left hand navigation menu, make sure you select the stage of your stack that you want to modify. Then, to see your runtime variables, click Runtime variables . Note : If you had TinyStacks create a database for your stage, you may already see some variables for connecting to your database defined here. You can add any key-value pair you wish to your stage. When done, click Save runtime variables to save your changes. Setting new runtime variables will trigger a rebuild of your stack's stage. Once the rebuild and redeploy is complete, the key-value pairs you defined will be exposed as environment variables on your Docker container. Your application code should be able to access these values the same as it would any other environment variable (e.g., process.env in Node.js or os.environ.get() in Python ). ...change my scale settings? When you create a stage, you can specify how you want your application to scale. If you need to change these at any time, you can do so through the stage's Settings page. Go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. You have two choices for adjusting scaling for your application. Click Endpoint to change how your application's endpoints are routed and load balanced on AWS. If you're currently using Amazon API Gateway but are beginning to handle more than 1 million requests/day, consider changing to Application Load Balancer instead. You may also desire to change how your Amazon ECS cluster scales. By default, TinyStacks will start two Amazon EC2 instances in your ECS cluster. We also define Amazon CloudWatch rules that implement the following behavior: If the aggregate CPU usage of your ECS cluster instances exceeds 75% for more than 15 minutes, AWS will automatically add another EC2 instances to the cluster. If the aggregate CPU usage of your ECS cluster instances is lower than 75% for more than 15 minutes, AWS will automatically remove an EC2 instance from the cluster. You may need to change these defaults if your application is either using too many underutilized resources or (more likely) is maxing out on available ECS cluster instances. To change scale settings, select Build and scale from the navigation menu on the Settings page. Here, you can change several settings. The first is your application's instance sizing . You can upgrade instance sizing if you are spinning up new ECS cluster instances too quickly. If you are currently using a t3.micro instance size, consider upgrading to an m3.medium or an m3.large. You can also adjust your autoscale min/max settings . The following settings are available to change: Desired capacity The number of ECS cluster instances to maintain if no auto scaling rules have been triggered by a CloudWatch alarm. The desired capacity should be set to a level that cna sustain normal, everyday traffic. If you set it too high, you will spend additional money on ECS cluster instances you aren't using. Conversely, if you set it too high, you may experience service interruptions, as it can take several minutes to initialize a new cluster instance. Min Capacity The minimum number of cluster instances to run regardless of auto scaling rules. As stated above, scaling up a new cluster instance can take time; setting a minimum number of instances ensures you always have \"warm\" cluster instances that are stood up and able to accept incoming traffic. Max Capacity The maximum number of cluster instances to run regardless of auto scaling rules. This setting provides an upper boundary beyond which your application will not scale, which is useful for controlling costs or responding to a potential denial of service attack. For more information on scaling of EC2 instances, see the AWS documentation . Note : Saving settings changes will trigger a rebuild of your stage. Your application may not be accessible on this stage until the rebuild and redeploy has completed. Changing any of the settings in this section may result in increased AWS service costs. ...change my stage's database settings? Go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will open the Settings * page. In the left hand column, under Stage , select the stage to which you want to add a database. Then, from the same column, select Database**. You will see two different screens here depending on whether your stage currently has a database or not. If it has a database, you will see a screen that enables you to change the instance type for your database as well as the amount of disk storage used. If your stage currently has no database, you will see the following screen. You can either add a new Postgres database, or add another existing AWS database to your stack. Note : Saving your changes will trigger a rebuild of your stage. Your application may not be accessible on this stage until the rebuild and redeploy has completed. ...connect to my Postgres database from my application? When you have TinyStacks create a Postgres database for you, we push all information about the database - including username and password - into a set of runtime variables. These are exposed to your application as environment variables in your Docker container instances. The variables pushed include: PG_HOST : The IP address PG_PORT : The port on which the Postgres database is running PG_CREDENTIALS_SECRET : The password for connecting to your Postgres database PG_DATABASE : The name of the database on the database host server Your application code should be able to access these values the same as it would any other environment variable (e.g., process.env in Node.js or os.environ.get() in Python ). ...delete a stack? To delete a stack, go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will land you on the Stack settings page. There, you will find a Delete button. Click it, and type delete in the dialog box when prompted to confirm the operation. ...delete a stage? To delete a stack, go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will land you on the Stack settings page. On the left hand navigation menu, under Stage settings , select the stage you want to delete. After this, select the Stage details link on the left hand navigation menu. There, you will find a Delete Stage button. Click it and, when prompted, enter delete to confirm the operation. Advanced How Do I ...add multiple Docker images to my stack? TinyStacks supports multiple Docker images in your stack. To add a second Docker image, after you create your stack, navigate to the Stack settings page via the gear icon from the Stacks dashboard. Under Stack settings, click the dropdown next to Service: , and click Create new service . You can use two different methods to add a new service: Repository . Specify a Git repository. TinyStacks will look for the same files it requires when building a Docker image for your primary stack. Image URL . Use an existing Docker image URL. The repository containing the image must either be public or a repository in an AWS account to which you have given TinyStacks access . Alternatively, instead of a URL, you can specify the image name and version of an image in the Docker public repository(e.g., python:3.9 ). Once you're done, click Create new service . When the stack rebuilds, it will deploy your second container side by side on the same EC2 instances as your other running tasks. The images will scale together as you change your auto-scale settings. If you add an additional EC2 instance to your ECS cluster, we will create a new instance of each image on this new ECS cluster node. Memory and CPU resources on the instance are evenly split between all running container images. ...change the exposed port for my application? TinyStacks needs to know which port your application is serving HTTP traffic over in order to configure your Amazon ECS tasks properly. If you are using a port besides the standard port 80, you will need to change it in TinyStacks. To change your port, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. On the Stack Settings page, under Port , input the number of the port on which your Docker container is exposing its services. ...connect to my Postgres database from outside of my application? On top of pushing Postgres database connection information to your application as runtime variables, Tinystacks stores your credentials securely in your AWS account using AWS Secrets Manager . You can see these secrets by navigating to AWS Secrets Manager in your AWS account. You can identify the correct secret for your application from the AWS Console in two ways: The Secret description of the stack, which will contain the name you gave your stack at stack creation time. The tag aws:cloudformation:stack-name , which will also contain the name of your secret. If you have multiple stages, you will have multiple secrets. You can distinguish them by the name of the secret, which will have the name of the stage pre-pended. In this example, since this is our Postgres database for our dev stage, it starts with te prefix dev . In the AWS Console, you can see the information stored in this secret by expanding the Secret value dropdown. There, you can see all of the information required to connect to your Postgres database. If you need to retrieve these values programmatically, you can do so using the AWS Command Line Interface (CLI) or any of the APIs available for programmatic access. For example, using the AWS CLI, you can retrieve the secret you need by searching for all secrets where the tag aws:cloudformation:stack-name matches your stack name. You can then use the command jq to filter out the return values to get the correct database for your stage. aws secretsmanager list-secrets --region us-east-1 --filters Key=tag-key Values=aws:cloudformation:stack-name Key=tag-value,Values=test-django2 | jq '.[][] | select(.Name|test(\"^dev\")) ...pass custom data to the build process? Your build.yml file controls how your container is built and then stored in Amazon ECR. Sometimes, you may need to pass custom data at build time when building your Docker image. You can accomplish this by defining build variables for your stack. To define build variables, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. On the Stack Settings page, click Build variables . Here you can define name-value pairs that you can reference in your build.yml file. ...deploy an application that uses a framework not directly supported by TinyStacks? While TinyStacks contains sample code for several popular application frameworks, our service is framework-agnostic. So long as your application can be packaged into a Docker container, it can run on TinyStacks! ....push custom Amazon CloudWatch logs from my application? By default, TinyStacks creates a CloudWatch Logs log group for you. Any application output written to standard output (e.g., console.log() in Node.js) will appear in this log. ...give my application permission to access other AWS services? As you grow your application, you will likely want to incorporate access to other AWS services. Common examples include DynamoDB for NoSQL data storage and Amazon S3 for storing blobs and other large data. Currently, there are two ways to do this on TinyStacks. Note that both operations require knowledge of AWS Identity and Access Management (IAM). Pass AWS credentials as runtime variables You can create an AWS access key and secret key and pass these variables as runtime variables as described above in passing runtime variables to a stage. Note that, if you do this, anyone with access to your TinyStacks account has access to these variables, and thus to your underlying AWS account. Please proceed with caution. Modify the IAM role for your application Your Amazon ECS tasks all run with an IAM task role that determines their AWS permissions. The task role name is a combination of the stack name, the stage name, and the phrase \"TaskRoleDefaultPolicy\". For example, below is the IAM role for the dev stage for a stack named test-django2 . By default, this role only has permission to push events to your Amazon CloudWatch Logs log group. You can modify it with a valid IAm policy to grant it access to additional AWS resources.","title":"How Do I...?"},{"location":"tinystacks-how-do-i/#basic-how-do-i","text":"","title":"Basic How Do I"},{"location":"tinystacks-how-do-i/#add-a-new-stage","text":"When TinyStacks created your stack, we created a single stage for you called dev . As discussed in our concepts documentation , your team will likely want at least two stages - one for development and one for production. This allows you to test changes in your dev stage before releasing them to customers. To add a second stage, navigate to your Stacks page and select your stack by clicking on its name. The next page will show all of the stages currently defined for your stack. To add a new stage, click the Add stage button. On the New stack stage screen, you can configure your new stage. In the next screenshot, we've supplied a sample dialog for a prod stage that we explain in detail below: Stage name . Must be unique within this stack. Should indicate the role that this stage plays in your stack - e.g., dev, test, staging, prod, etc. In this case, we use the name prod to represent our production stage. Database . Enables adding a new Postgres database or another existing Amazon RDS database to your stack. For now, we'll leave this option blank. Require manual approval . By default, if a change checked into a branch is built and deployed successfully by one stage, it will propagate automatically to the next stage. In most cases, however, your team will want to test and approve changes manually before pushing them into production. Since we're creating a production stage here, we'll check this box. Amazon API Gateway vs. Application Load Balancer . Here, you can choose how you want to route requests to your application based on whether you expect your application will need to operate at standard scale or hyperscale. For now, we'll leave this to the default of Amazon API Gateway. For more information on scale settings, consult our architectural overview . Enable caching . Whether to cache responses through API Gateway. This option is only available if using Amazon API Gateway. Once you've configured your stage to suit your needs, click Create new stage . The new stage will run and create, building the code that you most recently checked in to the stack's associated Git branch.","title":"...add a new stage?"},{"location":"tinystacks-how-do-i/#pass-custom-variables-and-configuration-data-to-each-stage","text":"It's likely that your application will need various runtime variables set in order to run. For example, you may need to supply credentials to a data store, such as DynamoDB, or information on how to connect to other microservices on which the application depends. Each stage of your application will likely need its own custom runtime variables, as the configuration and the resources to which your application connects will vary by stage. TinyStacks makes it easy to set runtime variables on your application that are unique to each stage. This enables you to have different configuration settings for your application depending on whether it's in dev, test, or production. To add or change runtime variables, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. In the Stage dropdown on the left hand navigation menu, make sure you select the stage of your stack that you want to modify. Then, to see your runtime variables, click Runtime variables . Note : If you had TinyStacks create a database for your stage, you may already see some variables for connecting to your database defined here. You can add any key-value pair you wish to your stage. When done, click Save runtime variables to save your changes. Setting new runtime variables will trigger a rebuild of your stack's stage. Once the rebuild and redeploy is complete, the key-value pairs you defined will be exposed as environment variables on your Docker container. Your application code should be able to access these values the same as it would any other environment variable (e.g., process.env in Node.js or os.environ.get() in Python ).","title":"...pass custom variables and configuration data to each stage?"},{"location":"tinystacks-how-do-i/#change-my-scale-settings","text":"When you create a stage, you can specify how you want your application to scale. If you need to change these at any time, you can do so through the stage's Settings page. Go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. You have two choices for adjusting scaling for your application. Click Endpoint to change how your application's endpoints are routed and load balanced on AWS. If you're currently using Amazon API Gateway but are beginning to handle more than 1 million requests/day, consider changing to Application Load Balancer instead. You may also desire to change how your Amazon ECS cluster scales. By default, TinyStacks will start two Amazon EC2 instances in your ECS cluster. We also define Amazon CloudWatch rules that implement the following behavior: If the aggregate CPU usage of your ECS cluster instances exceeds 75% for more than 15 minutes, AWS will automatically add another EC2 instances to the cluster. If the aggregate CPU usage of your ECS cluster instances is lower than 75% for more than 15 minutes, AWS will automatically remove an EC2 instance from the cluster. You may need to change these defaults if your application is either using too many underutilized resources or (more likely) is maxing out on available ECS cluster instances. To change scale settings, select Build and scale from the navigation menu on the Settings page. Here, you can change several settings. The first is your application's instance sizing . You can upgrade instance sizing if you are spinning up new ECS cluster instances too quickly. If you are currently using a t3.micro instance size, consider upgrading to an m3.medium or an m3.large. You can also adjust your autoscale min/max settings . The following settings are available to change: Desired capacity The number of ECS cluster instances to maintain if no auto scaling rules have been triggered by a CloudWatch alarm. The desired capacity should be set to a level that cna sustain normal, everyday traffic. If you set it too high, you will spend additional money on ECS cluster instances you aren't using. Conversely, if you set it too high, you may experience service interruptions, as it can take several minutes to initialize a new cluster instance. Min Capacity The minimum number of cluster instances to run regardless of auto scaling rules. As stated above, scaling up a new cluster instance can take time; setting a minimum number of instances ensures you always have \"warm\" cluster instances that are stood up and able to accept incoming traffic. Max Capacity The maximum number of cluster instances to run regardless of auto scaling rules. This setting provides an upper boundary beyond which your application will not scale, which is useful for controlling costs or responding to a potential denial of service attack. For more information on scaling of EC2 instances, see the AWS documentation . Note : Saving settings changes will trigger a rebuild of your stage. Your application may not be accessible on this stage until the rebuild and redeploy has completed. Changing any of the settings in this section may result in increased AWS service costs.","title":"...change my scale settings?"},{"location":"tinystacks-how-do-i/#change-my-stages-database-settings","text":"Go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will open the Settings * page. In the left hand column, under Stage , select the stage to which you want to add a database. Then, from the same column, select Database**. You will see two different screens here depending on whether your stage currently has a database or not. If it has a database, you will see a screen that enables you to change the instance type for your database as well as the amount of disk storage used. If your stage currently has no database, you will see the following screen. You can either add a new Postgres database, or add another existing AWS database to your stack. Note : Saving your changes will trigger a rebuild of your stage. Your application may not be accessible on this stage until the rebuild and redeploy has completed.","title":"...change my stage's database settings?"},{"location":"tinystacks-how-do-i/#connect-to-my-postgres-database-from-my-application","text":"When you have TinyStacks create a Postgres database for you, we push all information about the database - including username and password - into a set of runtime variables. These are exposed to your application as environment variables in your Docker container instances. The variables pushed include: PG_HOST : The IP address PG_PORT : The port on which the Postgres database is running PG_CREDENTIALS_SECRET : The password for connecting to your Postgres database PG_DATABASE : The name of the database on the database host server Your application code should be able to access these values the same as it would any other environment variable (e.g., process.env in Node.js or os.environ.get() in Python ).","title":"...connect to my Postgres database from my application?"},{"location":"tinystacks-how-do-i/#delete-a-stack","text":"To delete a stack, go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will land you on the Stack settings page. There, you will find a Delete button. Click it, and type delete in the dialog box when prompted to confirm the operation.","title":"...delete a stack?"},{"location":"tinystacks-how-do-i/#delete-a-stage","text":"To delete a stack, go to your Stacks page and, for the stack you want to modify, click the gear icon in the lower right corner. This will land you on the Stack settings page. On the left hand navigation menu, under Stage settings , select the stage you want to delete. After this, select the Stage details link on the left hand navigation menu. There, you will find a Delete Stage button. Click it and, when prompted, enter delete to confirm the operation.","title":"...delete a stage?"},{"location":"tinystacks-how-do-i/#advanced-how-do-i","text":"","title":"Advanced How Do I"},{"location":"tinystacks-how-do-i/#add-multiple-docker-images-to-my-stack","text":"TinyStacks supports multiple Docker images in your stack. To add a second Docker image, after you create your stack, navigate to the Stack settings page via the gear icon from the Stacks dashboard. Under Stack settings, click the dropdown next to Service: , and click Create new service . You can use two different methods to add a new service: Repository . Specify a Git repository. TinyStacks will look for the same files it requires when building a Docker image for your primary stack. Image URL . Use an existing Docker image URL. The repository containing the image must either be public or a repository in an AWS account to which you have given TinyStacks access . Alternatively, instead of a URL, you can specify the image name and version of an image in the Docker public repository(e.g., python:3.9 ). Once you're done, click Create new service . When the stack rebuilds, it will deploy your second container side by side on the same EC2 instances as your other running tasks. The images will scale together as you change your auto-scale settings. If you add an additional EC2 instance to your ECS cluster, we will create a new instance of each image on this new ECS cluster node. Memory and CPU resources on the instance are evenly split between all running container images.","title":"...add multiple Docker images to my stack?"},{"location":"tinystacks-how-do-i/#change-the-exposed-port-for-my-application","text":"TinyStacks needs to know which port your application is serving HTTP traffic over in order to configure your Amazon ECS tasks properly. If you are using a port besides the standard port 80, you will need to change it in TinyStacks. To change your port, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. On the Stack Settings page, under Port , input the number of the port on which your Docker container is exposing its services.","title":"...change the exposed port for my application?"},{"location":"tinystacks-how-do-i/#connect-to-my-postgres-database-from-outside-of-my-application","text":"On top of pushing Postgres database connection information to your application as runtime variables, Tinystacks stores your credentials securely in your AWS account using AWS Secrets Manager . You can see these secrets by navigating to AWS Secrets Manager in your AWS account. You can identify the correct secret for your application from the AWS Console in two ways: The Secret description of the stack, which will contain the name you gave your stack at stack creation time. The tag aws:cloudformation:stack-name , which will also contain the name of your secret. If you have multiple stages, you will have multiple secrets. You can distinguish them by the name of the secret, which will have the name of the stage pre-pended. In this example, since this is our Postgres database for our dev stage, it starts with te prefix dev . In the AWS Console, you can see the information stored in this secret by expanding the Secret value dropdown. There, you can see all of the information required to connect to your Postgres database. If you need to retrieve these values programmatically, you can do so using the AWS Command Line Interface (CLI) or any of the APIs available for programmatic access. For example, using the AWS CLI, you can retrieve the secret you need by searching for all secrets where the tag aws:cloudformation:stack-name matches your stack name. You can then use the command jq to filter out the return values to get the correct database for your stage. aws secretsmanager list-secrets --region us-east-1 --filters Key=tag-key Values=aws:cloudformation:stack-name Key=tag-value,Values=test-django2 | jq '.[][] | select(.Name|test(\"^dev\"))","title":"...connect to my Postgres database from outside of my application?"},{"location":"tinystacks-how-do-i/#pass-custom-data-to-the-build-process","text":"Your build.yml file controls how your container is built and then stored in Amazon ECR. Sometimes, you may need to pass custom data at build time when building your Docker image. You can accomplish this by defining build variables for your stack. To define build variables, go to your Stacks page . For the stack you want to modify, click the gear icon in the lower right corner. On the Stack Settings page, click Build variables . Here you can define name-value pairs that you can reference in your build.yml file.","title":"...pass custom data to the build process?"},{"location":"tinystacks-how-do-i/#deploy-an-application-that-uses-a-framework-not-directly-supported-by-tinystacks","text":"While TinyStacks contains sample code for several popular application frameworks, our service is framework-agnostic. So long as your application can be packaged into a Docker container, it can run on TinyStacks!","title":"...deploy an application that uses a framework not directly supported by TinyStacks?"},{"location":"tinystacks-how-do-i/#push-custom-amazon-cloudwatch-logs-from-my-application","text":"By default, TinyStacks creates a CloudWatch Logs log group for you. Any application output written to standard output (e.g., console.log() in Node.js) will appear in this log.","title":"....push custom Amazon CloudWatch logs from my application?"},{"location":"tinystacks-how-do-i/#give-my-application-permission-to-access-other-aws-services","text":"As you grow your application, you will likely want to incorporate access to other AWS services. Common examples include DynamoDB for NoSQL data storage and Amazon S3 for storing blobs and other large data. Currently, there are two ways to do this on TinyStacks. Note that both operations require knowledge of AWS Identity and Access Management (IAM). Pass AWS credentials as runtime variables You can create an AWS access key and secret key and pass these variables as runtime variables as described above in passing runtime variables to a stage. Note that, if you do this, anyone with access to your TinyStacks account has access to these variables, and thus to your underlying AWS account. Please proceed with caution. Modify the IAM role for your application Your Amazon ECS tasks all run with an IAM task role that determines their AWS permissions. The task role name is a combination of the stack name, the stage name, and the phrase \"TaskRoleDefaultPolicy\". For example, below is the IAM role for the dev stage for a stack named test-django2 . By default, this role only has permission to push events to your Amazon CloudWatch Logs log group. You can modify it with a valid IAm policy to grant it access to additional AWS resources.","title":"...give my application permission to access other AWS services?"}]}